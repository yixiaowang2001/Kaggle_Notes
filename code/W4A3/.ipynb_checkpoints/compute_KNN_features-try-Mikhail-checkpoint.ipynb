{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi! In this assignment you will need to implement features, based on nearest neighbours. \n",
    "\n",
    "KNN classifier (regressor) is a very powerful model, when the features are homogeneous and it is a very common practice to use KNN as first level model. In this homework we will extend KNN model and compute more features, based on nearest neighbors and their distances. \n",
    "\n",
    "You will need to implement a number of features, that were one of the keys, that leaded the instructors to prizes in Otto and Springleaf competitions. Of course, the list of features you will need to implement can be extended, in fact in competitions the list was at list 3 times larger, so when solving a real competition do not hesitate to make up your own features.   \n",
    "\n",
    "You can optionally implement parallel computations. Nearest neighbours are hard to compute so it is preferable to have a parallel version of all algorithms. Is is really a cool skill to have to know how to use multiprocessing, so you can try it here.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check your versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.13.1\n",
      "pandas 0.20.3\n",
      "sklearn 0.19.0\n",
      "scipy 0.19.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sklearn\n",
    "import scipy.sparse \n",
    "\n",
    "for p in [np, pd, sklearn, scipy]:\n",
    "    print (p.__name__, p.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The versions should be not less than:\n",
    "\n",
    "    numpy 1.13.1\n",
    "    pandas 0.20.3\n",
    "    sklearn 0.19.0\n",
    "    scipy 0.19.1\n",
    "    \n",
    "If it is not the case, uncomment the following cell and run it. Then restart the kernel and check versions again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!conda update -y scikit-learn pandas scipy numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = '../readonly/KNN_features_data/X.npz'\n",
    "train_labels = '../readonly/KNN_features_data/Y.npy'\n",
    "\n",
    "test_path = '../readonly/KNN_features_data/X_test.npz'\n",
    "test_labels = '../readonly/KNN_features_data/Y_test.npy'\n",
    "\n",
    "# Train data\n",
    "X = scipy.sparse.load_npz(train_path)\n",
    "Y = np.load(train_labels)\n",
    "\n",
    "# Test data\n",
    "X_test = scipy.sparse.load_npz(test_path)\n",
    "Y_test = np.load(test_labels)\n",
    "\n",
    "# Out-of-fold features we loaded above were generated with n_splits=4 and skf seed 123\n",
    "# So it is better to use seed 123 for generating KNN features as well \n",
    "skf_fold = 123\n",
    "n_splits = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you need to implement features, based on nearest neaighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# This class should implement KNN features extraction \n",
    "class NearestNeighborsFeats(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_jobs, k_list, metric, n_classes=None, n_neighbors=None, eps=1e-6):\n",
    "        self.n_jobs = n_jobs\n",
    "        self.k_list = k_list\n",
    "        self.metric = metric\n",
    "        \n",
    "        if n_neighbors is None:\n",
    "            self.n_neighbors = max(k_list) \n",
    "        else:\n",
    "            self.n_neighbors = n_neighbors\n",
    "            \n",
    "        self.eps = eps        \n",
    "        self.n_classes_ = n_classes\n",
    "        print(self.n_classes_)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Create a NearestNeighbors (NN) object. We will use it in `predict` function \n",
    "        self.NN = NearestNeighbors(n_neighbors=max(self.k_list), \n",
    "                                      metric=self.metric, \n",
    "                                      n_jobs=1, \n",
    "                                      algorithm='brute' if self.metric=='cosine' else 'auto')\n",
    "        self.NN.fit(X)\n",
    "        \n",
    "        # Store labels \n",
    "        self.y_train = y\n",
    "        \n",
    "        # Save how many classes we have\n",
    "        self.n_classes = np.unique(y).shape[0] if self.n_classes_ is None else self.n_classes_\n",
    "        self.n_classes_ = self.n_classes\n",
    "        \n",
    "        \n",
    "    def get_features_for_one(self, x):\n",
    "        '''\n",
    "            x is of shape (L,)\n",
    "        '''\n",
    "        ## NOTE: WTF self.NN ??\n",
    "        NN_output = self.NN.kneighbors(x)\n",
    "        \n",
    "        # Vector of size `n_neighbors`\n",
    "        # Stores indices of the neighbors\n",
    "        neighs = NN_output[1][0]\n",
    "        \n",
    "        # Vector of size `n_neighbors`\n",
    "        # Stores distances to corresponding neighbors\n",
    "        neighs_dist = NN_output[0][0] \n",
    "\n",
    "        # Vector of size `n_neighbors`\n",
    "        # Stores labels of corresponding neighbors\n",
    "        neighs_y = self.y_train[neighs] \n",
    "        \n",
    "        ## ========================================== ##\n",
    "        ##              YOUR CODE BELOW\n",
    "        ## ========================================== ##\n",
    "        \n",
    "        # We will accumulate the computed features here\n",
    "        # Eventually it will be a list of lists or np.arrays\n",
    "        # and we will use np.hstack to concatenate those\n",
    "        return_list = [] \n",
    "        \n",
    "        # ----------------------------------------------\n",
    "        # 1. Fraction of objects of every class.\n",
    "        #    It is basically a KNNÐ¡lassifiers predictions.\n",
    "        #    take a look at np.bincount function, it can be very helpful\n",
    "        #    note that the values should sum up to one\n",
    "        for k in self.k_list:\n",
    "            feat = np.zeros(self.n_classes_)\n",
    "            for i in range(self.n_classes_):\n",
    "                feat[i] = np.mean(neighs_y == i)\n",
    "            assert len(feat) == self.n_classes\n",
    "            return_list += [feat]\n",
    "        \n",
    "        # ----------------------------------------------\n",
    "        # 2.  Streak: how many closest objects have same label\n",
    "        #     We need to be careful with the case when all neighbors are of the same class\n",
    "        #     Answer 'res' is list of size 1\n",
    "        #     What can help you:\n",
    "        #     np.where, list.index(), map\n",
    "        \n",
    "        ## NOTE: same to what??\n",
    "        ## NOTE: answer not is \"res\", but \"out\"\n",
    "        \n",
    "        cnt = {}\n",
    "        for y in neighs_y:\n",
    "            cnt[y] = cnt.get(y, 0) + 1\n",
    "        max_class = max(cnt, key=cnt.get)\n",
    "        out = [max_class]\n",
    "        assert len(out) == 1\n",
    "        return_list += [out]\n",
    "        \n",
    "        # ----------------------------------------------\n",
    "        # 3. Minimum distance to objects of each class\n",
    "        #    Finds first instance of a class and take it's distance as features.\n",
    "        #    `out` is a list of size `n_class`\n",
    "        #    If there are no neighbouring objects of some classes, \n",
    "        #    Then set distance to that class to be max distance + 1\n",
    "        #    `np.where` might be helpful\n",
    "        \n",
    "        out = []\n",
    "        for c in range(self.n_classes):\n",
    "            out.append(max([d for y, d in zip(neighs_y, neighs_dist) if y == c] + [-42]))\n",
    "        out = np.array(out)\n",
    "        max_dist = max(out)\n",
    "        out[out == -42] = max_dist + 1\n",
    "        \n",
    "        assert len(out) == self.n_classes\n",
    "        return_list += [out]\n",
    "        \n",
    "        # ----------------------------------------------\n",
    "        # 4. Minimum *normalized* distance to objects of each class\n",
    "        #    As 3. but we normalize (divide) the distances\n",
    "        #    by distance to the closest neighbor\n",
    "        #    Do not forget to add self.eps to denominator\n",
    "        \n",
    "        out = []\n",
    "        min_dist = min(neighs_dist) + self.eps\n",
    "        for c in range(self.n_classes):\n",
    "            curr_class_distances= [d for y, d in zip(neighs_y, neighs_dist) if y == c]\n",
    "            if len(curr_class_distances) > 0:\n",
    "                out.append(min(curr_class_distances) / min_dist)\n",
    "            else:\n",
    "                out.append(0)\n",
    "        \n",
    "        return_list += [out]\n",
    "        \n",
    "        # ----------------------------------------------\n",
    "        # 5. \n",
    "        #    5.1 Distance to Kth neighbor\n",
    "        #        Think of this as of quantiles of a distribution\n",
    "        #    5.2 Distance to Kth neighbor normalized by \n",
    "        #        distance to the first neighbor\n",
    "        #    \n",
    "        #    feat_51, feat_52 are answers to 5.1. and 5.2\n",
    "        #    should be scalars\n",
    "        for k in self.k_list:\n",
    "            \n",
    "            feat_51 = neighs_dist[k-1]\n",
    "            feat_52 = neighs_dist[k-1] / (neighs_dist[0] + self.eps)\n",
    "            return_list += [[feat_51, feat_52]]\n",
    "        \n",
    "        # ----------------------------------------------\n",
    "        # 6. Mean distance to first K neighbors per class \n",
    "        # \n",
    "        #    You can use np.bincount with appropriate weights\n",
    "        #    Don't forget, that if you divide by something, \n",
    "        #    You need to add self.eps to denominator\n",
    "        \n",
    "        for k in self.k_list:\n",
    "            feat = []\n",
    "            for c in range(self.n_classes):\n",
    "                curr_class_distances = [d for y, d in zip(neighs_y, neighs_dist) if y == c][:k]\n",
    "            if len(curr_class_distances) > 0:\n",
    "                feat.append(np.mean(curr_class_distances))\n",
    "            else:\n",
    "                feat.append(999)\n",
    "            \n",
    "            # NOTE: what to do with missing classses? 0? 1000?\n",
    "            # NOTE: it is not clear what is the dimentionality of feat\n",
    "            return_list += [feat]\n",
    "        \n",
    "        \n",
    "        # merge\n",
    "        knn_feats = np.hstack(return_list)\n",
    "        print(knn_feats.shape)\n",
    "        \n",
    "        ## NOTE: invalid syntax.\n",
    "        assert knn_feats.shape == (239,) \n",
    "        return knn_feats\n",
    "    \n",
    "    \n",
    "            \n",
    "        \n",
    "    def predict(self, X):   \n",
    "        '''\n",
    "            Produces KNN features for every object of a dataset X\n",
    "        '''\n",
    "        if self.n_jobs == 1:\n",
    "            test_feats = []\n",
    "            for i in range(X.shape[0]):\n",
    "                test_feats.append(self.get_features_for_one(X[i:i+1]))\n",
    "        else:\n",
    "            # Try to make it parallel \n",
    "            # You can use whatever you want to do it\n",
    "            #\n",
    "            # But I suggest you to use multiprocessing.Pool here.\n",
    "            # As I could not get joblib working\n",
    "            #\n",
    "            # Number of threads should be controlled by self.n_jobs \n",
    "            # To make it work you will need to read this \n",
    "            # http://qingkaikong.blogspot.ru/2016/12/python-parallel-method-in-class.html\n",
    "            # assert False, 'Not implemented, use n_jobs=1'\n",
    "            \n",
    "            from multiprocessing.dummy import Pool\n",
    "            \n",
    "            pool = Pool(processes=self.n_jobs)\n",
    "            test_feats = pool.map(self.get_features_for_one, X)\n",
    "\n",
    "        return np.vstack(test_feats)\n",
    "\n",
    "# http://qingkaikong.blogspot.ru/2016/12/python-parallel-method-in-class.html\n",
    "def unwrap_self(arg, **kwarg):\n",
    "    return NearestNeighborsFeats.get_features_for_one(*arg, **kwarg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure you've implemented everything correctly we provide you the correct features for the first 50 objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "(155,)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-990d0b23ff5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Get features for test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtest_knn_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNNF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# This should be zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-934aec9b8f7f>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mtest_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mtest_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features_for_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;31m# Try to make it parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-934aec9b8f7f>\u001b[0m in \u001b[0;36mget_features_for_one\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m## NOTE: invalid syntax.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mknn_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m239\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mknn_feats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load correct features\n",
    "true_knn_feats_first50 = np.load('../readonly/KNN_features_data/knn_feats_test_first50.npy')\n",
    "\n",
    "## NOTE: what is k_list??\n",
    "\n",
    "# a list of K in KNN \n",
    "k_list = [3, 8,32]\n",
    "\n",
    "## NOTE: 0- or 1-based indexing???\n",
    "\n",
    "\n",
    "# Create instance of our KNN feature extractor\n",
    "NNF = NearestNeighborsFeats(n_jobs=1, k_list=k_list, metric='minkowski')\n",
    "\n",
    "# Fit on train set\n",
    "NNF.fit(X,Y)\n",
    "\n",
    "# Get features for test\n",
    "test_knn_feats = NNF.predict(X_test[:50])\n",
    "\n",
    "# This should be zero\n",
    "print (np.abs(test_knn_feats - true_knn_feats_first50).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement parallel computations and compute features for the train and test sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features for test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute features for the whole test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for m in ['minkowski', 'cosine']:\n",
    "    print m\n",
    "    \n",
    "    # Create instance of our KNN feature extractor\n",
    "    NNF = NearestNeighborsFeats(n_jobs=20, k_list=k_list, metric=m)\n",
    "    \n",
    "    # Fit on train set\n",
    "    NNF.fit(X,Y)\n",
    "\n",
    "    # Get features for test\n",
    "    test_knn_feats = NNF.predict(X_test)\n",
    "    \n",
    "    # Dump the features to disk\n",
    "    np.save('data/knn_feats_test.npy', test_knn_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features for train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute features for train, using out-of-fold strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Differently from other homework we will not implement OOF predictions ourselves\n",
    "# but use sklearn's `cross_val_predict`\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# a list of K in KNN \n",
    "k_list = [3, 8,32]\n",
    "\n",
    "# We will use two metrics for KNN\n",
    "for m in ['minkowski', 'cosine']:\n",
    "    print m\n",
    "    \n",
    "    # Set up splitting scheme, use StratifiedKFold\n",
    "    # use skf_seed and n_splits defined above\n",
    "    skf = # YOUR CODE GOES HERE\n",
    "    \n",
    "    # Create instance of our KNN feature extractor\n",
    "    # n_jobs can be larger than the number of cores\n",
    "    NNF = NearestNeighborsFeats(n_jobs=10, k_list=k_list, metric=m)\n",
    "    \n",
    "    # Get KNN features using OOF use cross_val_predict with right parameters\n",
    "    preds = # YOUR CODE GOES HERE\n",
    "    \n",
    "    # Save the features\n",
    "    np.save('data/knn_feats_train.npy', preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to submit..."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
