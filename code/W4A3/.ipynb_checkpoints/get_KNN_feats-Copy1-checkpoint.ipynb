{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.13.1\n",
      "pandas 0.20.3\n",
      "sklearn 0.19.0\n",
      "scipy 0.19.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sklearn\n",
    "import scipy.sparse \n",
    "\n",
    "for p in [np, pd, sklearn, scipy]:\n",
    "    print (p.__name__, p.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The versions should be not less than:\n",
    "\n",
    "    numpy 1.13.1\n",
    "    pandas 0.20.3\n",
    "    sklearn 0.19.0\n",
    "    scipy 0.19.1\n",
    "    \n",
    "If it is not the case, uncomment the following cell and run it. Then restart the kernel and check versions again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda update -y scikit-learn pandas scipy numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../readonly/KNN_features_data/X.npz'\n",
    "train_labels = '../readonly/KNN_features_data/Y.npy'\n",
    "\n",
    "test_path = '../readonly/KNN_features_data/X_test.npz'\n",
    "test_labels = '../readonly/KNN_features_data/Y_test.npy'\n",
    "\n",
    "# Train data\n",
    "X = scipy.sparse.load_npz(train_path)\n",
    "Y = np.load(train_labels)\n",
    "\n",
    "# Test data\n",
    "X_test = scipy.sparse.load_npz(test_path)\n",
    "Y_test = np.load(test_labels)\n",
    "\n",
    "# Out-of-fold features we loaded above were generated with n_splits=4 and skf seed 123\n",
    "# So it is better to use seed 123 for generating KNN features as well \n",
    "skf_fold = 123\n",
    "n_splits = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you need to implement features, based on nearest neaighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-15cd3b16df39>, line 68)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-15cd3b16df39>\"\u001b[0;36m, line \u001b[0;32m68\u001b[0m\n\u001b[0;31m    out = # YOUR CODE GOES HERE\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# This class should implement KNN features extraction \n",
    "class NearestNeighborsFeats(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_jobs, k_list, metric, n_classes=None, n_neighbors=None, eps=1e-6):\n",
    "        self.n_jobs = n_jobs\n",
    "        self.k_list = k_list\n",
    "        self.metric = metric\n",
    "        \n",
    "        if n_neighbors is None:\n",
    "            self.n_neighbors = max(k_list) \n",
    "        else:\n",
    "            self.n_neighbors = n_neighbors\n",
    "            \n",
    "        self.eps = eps        \n",
    "        self.n_classes_ = n_classes\n",
    "        \n",
    "        \n",
    "    def get_features_for_one(self, x):\n",
    "        '''\n",
    "            x is of shape (L,)\n",
    "        '''\n",
    "\n",
    "        NN_output = self.NN.kneighbors(x)\n",
    "        \n",
    "        # Vector of size `n_neighbors`\n",
    "        # Stores indices of the neighbors\n",
    "        neighs = NN_output[1][0]\n",
    "        \n",
    "        # Vector of size `n_neighbors`\n",
    "        # Stores distances to corresponding neighbors\n",
    "        neighs_dist = NN_output[0][0] \n",
    "\n",
    "        # Vector of size `n_neighbors`\n",
    "        # Stores labels of corresponding neighbors\n",
    "        neighs_y = self.y_train[neighs] \n",
    "        \n",
    "        ## ========================================== ##\n",
    "        ##              YOUR CODE BELOW\n",
    "        ## ========================================== ##\n",
    "        \n",
    "        # We will accumulate the computed features here\n",
    "        # Eventually it will be a list of lists or np.arrays\n",
    "        # and we will use np.hstack to concatenate those\n",
    "        return_list = [] \n",
    "        \n",
    "        # ----------------------------------------------\n",
    "        # 1. Fraction of objects of every class.\n",
    "        #    It is basically a KNNÐ¡lassifiers predictions.\n",
    "        #    take a look at np.bincount function, it can be very helpful\n",
    "        #    note that the values should sum up to one\n",
    "        for k in self.k_list:\n",
    "            # YOUR CODE GOES HERE\n",
    "            \n",
    "            assert len(feat) == self.n_classes\n",
    "            return_list += [feat]\n",
    "        \n",
    "        # ----------------------------------------------\n",
    "        # 2.  Streak: how many closest objects have same label\n",
    "        #     We need to be careful with the case when all neighbors are of the same class\n",
    "        #     Answer 'res' is list of size 1\n",
    "        #     What can help you:\n",
    "        #     np.where, list.index(), map\n",
    "        \n",
    "        out = # YOUR CODE GOES HERE\n",
    "        \n",
    "        assert len(out) == 1\n",
    "        return_list += [out]\n",
    "        \n",
    "        # ----------------------------------------------\n",
    "        # 3. Minimum distance to objects of each class\n",
    "        #    Finds first instance of a class and take it's distance as features.\n",
    "        #    `out` is a list of size `n_class`\n",
    "        #    If there are no neighbouring objects of some classes, \n",
    "        #    Then set distance to that class to be max distance + 1\n",
    "        #    `np.where` might be helpful\n",
    "        \n",
    "        out = []\n",
    "        for c in range(self.n_classes):\n",
    "            # YOUR CODE GOES HERE\n",
    "        \n",
    "        assert len(out) == self.n_classes\n",
    "        return_list += [out]\n",
    "        \n",
    "        # ----------------------------------------------\n",
    "        # 4. Minimum *normalized* distance to objects of each class\n",
    "        #    As 3. but we normalize (divide) the distances\n",
    "        #    by distance to the closest neighbor\n",
    "        #    Do not forget to add self.eps to denominator\n",
    "        \n",
    "        out = []\n",
    "        for c in range(self.n_classes):\n",
    "            # YOUR CODE GOES HERE\n",
    "        \n",
    "        return_list += [out]\n",
    "        \n",
    "        # ----------------------------------------------\n",
    "        # 5. \n",
    "        #    5.1 Distance to Kth neighbor\n",
    "        #        Think of this as of quantiles of a distribution\n",
    "        #    5.2 Distance to Kth neighbor normalized by \n",
    "        #        distance to the first neighbor\n",
    "        #    \n",
    "        #    feat_51, feat_52 are answers to 5.1. and 5.2\n",
    "        #    should be scalars\n",
    "        for k in self.k_list:\n",
    "            \n",
    "            feat_51 = # YOUR CODE GOES HERE\n",
    "            feat_52 = # YOUR CODE GOES HERE\n",
    "            return_list += [[feat_51, feat_52]]\n",
    "        \n",
    "        # ----------------------------------------------\n",
    "        # 6. Mean distance to first K neighbors per class \n",
    "        # \n",
    "        #    You can use np.bincount with appropriate weights\n",
    "        #    Don't forget, that if you divide by something, \n",
    "        #    You need to add self.eps to denominator\n",
    "        \n",
    "        for k in self.k_list:\n",
    "            \n",
    "            # YOUR CODE GOES IN HERE\n",
    "            \n",
    "            return_list += [feat]\n",
    "        \n",
    "        \n",
    "        # merge\n",
    "        knn_feats = np.hstack(return_list)\n",
    "        \n",
    "        assert knn_feats.shape == (239), \n",
    "        return knn_feats\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Create a NearestNeighbors (NN) object. We will use it in `predict` function \n",
    "        self.NN = NearestNeighbors(n_neighbors=max(self.k_list), \n",
    "                                      metric=self.metric, \n",
    "                                      n_jobs=1, \n",
    "                                      algorithm='brute' if self.metric=='cosine' else 'auto')\n",
    "        self.NN.fit(X)\n",
    "        \n",
    "        # Store labels \n",
    "        self.y_train = y\n",
    "        \n",
    "        # Save how many classes we have\n",
    "        self.n_classes = np.unique(y).shape[0] if self.n_classes_ is None else self.n_classes_\n",
    "            \n",
    "        \n",
    "    def predict(self, X):       \n",
    "        if self.n_jobs == 1:\n",
    "            test_feats = []\n",
    "            for i in range(X.shape[0]):\n",
    "                test_feats.append(self.get_features_for_one(X[i:i+1]))\n",
    "        else:\n",
    "            # Try to make it parallel \n",
    "            # You can use whatever you want to do it\n",
    "            #\n",
    "            # But I suggest you to use multiprocessing.Pool here.\n",
    "            # As I could not get joblib working\n",
    "            #\n",
    "            # Number of threads should be controlled by self.n_jobs \n",
    "            # To make it work you will need to read this \n",
    "            # http://qingkaikong.blogspot.ru/2016/12/python-parallel-method-in-class.html\n",
    "            assert False, 'Not implemented, use n_jobs=1'\n",
    "            # YOUR CODE GOES HERE\n",
    "            # test_feats =  # YOUR CODE GOES HERE\n",
    "            # YOUR CODE GOES HERE\n",
    "            \n",
    "        return np.vstack(test_feats)\n",
    "\n",
    "# http://qingkaikong.blogspot.ru/2016/12/python-parallel-method-in-class.html\n",
    "def unwrap_self(arg, **kwarg):\n",
    "    return NearestNeighborsFeats.get_features_for_one(*arg, **kwarg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure you've implemented everything correctly we provide you the correct features for the first 50 objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NearestNeighborsFeats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-934389c17eb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create instance of our KNN feature extractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mNNF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNearestNeighborsFeats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minkowski'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Fit on train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NearestNeighborsFeats' is not defined"
     ]
    }
   ],
   "source": [
    "# Load correct features\n",
    "true_knn_feats_first50 = np.load('../readonly/KNN_features_data/knn_feats_test_first50.npy')\n",
    "\n",
    "# Create instance of our KNN feature extractor\n",
    "NNF = NearestNeighborsFeats(n_jobs=1, k_list=k_list, metric='minkowski')\n",
    "\n",
    "# Fit on train set\n",
    "NNF.fit(X,Y)\n",
    "\n",
    "# Get features for test\n",
    "test_knn_feats = NNF.predict(X_test[:50])\n",
    "\n",
    "# This should be zero\n",
    "print (np.abs(test_knn_feats - true_knn_feats_first50).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement parallel computations and compute features for the train and test sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minkowski\n",
      "cosine\n"
     ]
    }
   ],
   "source": [
    "for m in ['minkowski', 'cosine']:\n",
    "    print m\n",
    "    \n",
    "    # Create instance of our KNN feature extractor\n",
    "    NNF = NearestNeighborsFeats(n_jobs=20, k_list=k_list, metric=m)\n",
    "    \n",
    "    # Fit on train set\n",
    "    NNF.fit(X,Y)\n",
    "\n",
    "    # Get features for test\n",
    "    test_knn_feats = NNF.predict(X_test)\n",
    "    \n",
    "    # Dump the features to disk\n",
    "    np.save('data/knn_feats_test.npy', test_knn_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features for train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute features for train, using out-of-fold strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minkowski\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   20.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   30.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   41.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   41.2s finished\n",
      "cosine\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   21.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   32.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   43.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   43.3s finished\n"
     ]
    }
   ],
   "source": [
    "# Differently from other homework we will not implement OOF predictions ourselves\n",
    "# but use sklearn's `cross_val_predict`\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# a list of K in KNN \n",
    "k_list = [3, 8,32]\n",
    "\n",
    "# We will use two metrics for KNN\n",
    "for m in ['minkowski', 'cosine']:\n",
    "    print m\n",
    "    \n",
    "    # Set up splitting scheme, use StratifiedKFold\n",
    "    # use skf_seed and n_splits defined above\n",
    "    skf = # YOUR CODE GOES HERE\n",
    "    \n",
    "    # Create instance of our KNN feature extractor\n",
    "    # n_jobs can be larger than the number of cores\n",
    "    NNF = NearestNeighborsFeats(n_jobs=10, k_list=k_list, metric=m)\n",
    "    \n",
    "    # Get KNN features using OOF use cross_val_predict with right parameters\n",
    "    preds = # YOUR CODE GOES HERE\n",
    "    \n",
    "    # Save the features\n",
    "    np.save('data/knn_feats_train.npy', preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to submit..."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
