{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this programming assignment we will illustrate a very severe data leakge, that can often be found in competitions, where the pairs of object should be compared. The data in this assignment is taken from a real competition, and the funniest thing is that we will not use training set at all and achieve almost 100% accuracy score! We will just exploit the leakage.\n",
    "\n",
    "Now go through the notebook and complete the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the test data. Note, that we don't have any training data here, just test data. Moreover, we will even do not use any features of test objects. All we need to solve the task is the file with the indices for the pairs, we need to compare."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# непонятно, что это за файл вообще. То есть, зачем он нужен? Надо пояснить, что он используется для сабмита и сделать дамми колонку с предикшенами 0.5. ага, вижу, ты внизу это рассказал, но здесь у меня возник такой вопрос и я начал пытаться понять, что происходит"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FirstId</th>\n",
       "      <th>SecondId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1427</td>\n",
       "      <td>8053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17044</td>\n",
       "      <td>7681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19237</td>\n",
       "      <td>20966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8005</td>\n",
       "      <td>20765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16837</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3657</td>\n",
       "      <td>12504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2836</td>\n",
       "      <td>7582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6136</td>\n",
       "      <td>6111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23295</td>\n",
       "      <td>9817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6621</td>\n",
       "      <td>7672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FirstId  SecondId\n",
       "0     1427      8053\n",
       "1    17044      7681\n",
       "2    19237     20966\n",
       "3     8005     20765\n",
       "4    16837       599\n",
       "5     3657     12504\n",
       "6     2836      7582\n",
       "7     6136      6111\n",
       "8    23295      9817\n",
       "9     6621      7672"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test_pairs.csv')\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can think that there is a test dataset of images, and each image is assigned a unique `image_id` from $0$ to $N-1$ (N -- is the number of images). In the dataframe from above `FirstId` and `SecondId` point to these `image_id`'s and define pairs, that we should compare: e.g. do both images in the pair belong to the same class or not. So, for example for the first row: if images with `image_id=1427` and `image_id=8053` belong to the same class, we should predict $1$, and $0$ otherwise.   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# As we already know, key to data leakages discover is in careful EDA. So lets start our work with some basic data exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, check, how many different `image_id`s are there: print number of unique elements in `FirstId` column, minimum and maximum value for `FirstId` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26325"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "# ошибочно, но вероятно, так многие ответят\n",
    "print test.FirstId.nunique()\n",
    "# правильно # то же число; хм!\n",
    "len(np.unique(list(test.FirstId) + list(test.SecondId)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then print how many pairs we need to classify (it is basically the number of rows in the test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(368550, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print, how many distinct pairs it would be possible to create out of all images in the dataset?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346489650"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "26325 * (26325-1) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So the number of pairs we are given to classify is very very small compared to the total number of pairs. And obviously, the number of pairs with a label `1` will be much less than a number of pairs with label `0`. But let's check what do we have in case of our test set.\n",
    "\n",
    "To get a fraction of objects of class `1` we just need to submit a constant prediction: either all ones, or all zeros."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# на obviously я задумался немного. Вроде да, очевидно, если прикинуть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "const_pred = pd.DataFrame(test.index, columns = ['Id'])\n",
    "const_pred['Prediction'] = # YOUR CODE GOES HERE\n",
    "\n",
    "const_pred.to_csv('constant_submission.csv', drop=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# иструкции по сабмиту?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you see, the dataset constructed not by sampling random pairs, but with a specific algorithm. Pairs of class `1` are oversampled.\n",
    "So we can exploit this fact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incidence matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build an incidence matrix, you can think of pairs (FirstId, SecondId) as of edges in a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.sparse.coo_matrix([1] * len(test), (test.FirstId, test.SecondId)).data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.sparse.coo_matrix([1,1], ([0,0], [0,0])).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inc_mat.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.fmin(inc_mat.data, 1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(368538, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testU.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = pd.concat([test.FirstId, test.SecondId])\n",
    "second = pd.concat([test.SecondId, test.FirstId])\n",
    "testU = pd.DataFrame({'FirstId': first.values, 'SecondId': second.values}).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-980e2e8a83e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Sanity checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0minc_mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0minc_mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m736872\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Use scipy.sparse.coo_matrix((data, (i, j))) constructor\n",
    "# Note, that the matrix should be symmetric. It is not necessary for the matrix to be symmetric\n",
    "# It is convenient to convert matrix to `csr` format eventually\n",
    "\n",
    "# testU = test.copy().drop_duplicates()\n",
    "\n",
    "inc_mat = scipy.sparse.coo_matrix(([1] * len(testU) * 2,\n",
    "                                   (list(testU.FirstId) + list(testU.SecondId),\n",
    "                                    list(testU.SecondId) + list(testU.FirstId)),\n",
    "                                 ))\n",
    "# inc_mat.data = np.fmin(inc_mat.data, 1)\n",
    "# YOUR CODE GOES HERE (but probably you will need to write few more lines before)\n",
    "\n",
    "# Sanity checks\n",
    "assert inc_mat.max() == 1\n",
    "assert inc_mat.sum() == 736872"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-b36cb5ce2ea8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Sanity check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0minc_mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m737100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "v = len(np.unique(np.r_[test.FirstId.values,test.SecondId.values]))\n",
    "inc_mat = sparse.lil_matrix((v, v))\n",
    "\n",
    "for i in range(len(test)):\n",
    "    id1 = test['FirstId'].values[i]\n",
    "    id2 = test['SecondId'].values[i]\n",
    "    \n",
    "    inc_mat[id1, id2] = 1\n",
    "    inc_mat[id2, id1] = 1\n",
    "    \n",
    "        \n",
    "# Sanity check\n",
    "assert inc_mat.sum() == 737100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(736872.0, (736872, 2))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inc_mat.sum(), testU.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_second = pd.concat([test.FirstId, test.SecondId])\n",
    "second_first = pd.concat([test.SecondId, test.FirstId])\n",
    "\n",
    "inc_mat = scipy.sparse.coo_matrix(([1]*(len(first_second)), (first_second, second_first))).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now build the magic feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's think of the rows in the incidence matix as of representations for the objects. `i-th` row is a representation for an object with `image_id = i`. Then, to measure similarity between two objects we can measure similarity of their representations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, first select the rows from incidence matrix, that correspond to `FirstId`, and `SecondId`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# вот здесь непонятно, что это за Firstid. Напиши, что это test.FirstId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note, scipy goes crazy if a matrix is idexed with pandas' series. \n",
    "# So do not forget to convert series to np.array\n",
    "# These lines should run very quickly \n",
    "\n",
    "rows_FirstId   = inc_mat[test.FirstId.values]# YOUR CODE GOES HERE\n",
    "rows_SecondId  = inc_mat[test.SecondId.values]# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now compute *dot product* between corresponding rows in `rows_FirstId` and `rows_SecondId` matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "пробовал тут сначала scipy.multiply, memory error, наверное она в денс переводит сначала\n",
    "rows_FirstId.dot тоже ошибку выдает (он вообще не правильный, а у тебя написано выше dot multiplication, это разве то?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, that in order to do pointwise multiplication in scipy you need to use function `multiply`\n",
    "# regular `*` corresponds to matrix multiplication (???????? which matrix multiplication? elementwise??)\n",
    "\n",
    "f = rows_FirstId.multiply(rows_SecondId).mean(1)\n",
    "\n",
    "# Sanity check\n",
    "# assert f.shape == (368550, ) \n",
    "#точно так? у меня вот f.shape == (368550, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(368550, 1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's examine the feature, print frequncies (or counts) of each value in the feature `f`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зачем? тоже заранее не совсем понятно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For example use np.unique function, check for flags\n",
    "\n",
    "print # YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000760    182889\n",
       "0.000532    182035\n",
       "0.000570      2046\n",
       "0.000798       742\n",
       "0.000836       533\n",
       "0.001368       164\n",
       "0.001064        52\n",
       "0.001140        35\n",
       "0.000608        14\n",
       "0.001330        14\n",
       "0.000874        13\n",
       "0.002507         4\n",
       "0.001102         2\n",
       "0.001368         2\n",
       "0.002507         2\n",
       "0.001406         2\n",
       "0.001216         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(np.array(f).flatten()).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see how this feature clusters the pairs? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now finally, how do we get predictions? We do not have a train set to learn a model, but we have a piece of information about test set: the baseline accuracy score is very close to 0.5. And we also have a very strong considerations about the data generative process, so probably we will be fine even without train set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may try to choose a thresold, and set the predictions to 1, if the feature value `f` is higer than the threshold, and 0 otherwise. What threshold would you choose? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = f > 0.0006# SET THRESHOLD HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print mean value of the predictions, it should be very close to the accuracy score of the baseline, isn't it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.500526387193\n"
     ]
    }
   ],
   "source": [
    "print pred.mean()# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, let's create a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = test.loc[:,['Id']]\n",
    "submission['Prediction'] = pred.astype(int)\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now submit it to the leaderboard! If you did it right, the score should be very high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally:** try to explain to yourself, why the whole thing worked out. In fact, there is no magic in this feature, and the idea to use rows in the incidence matrix can be intuitively explainded."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "вот это кстати тоже норм вариант. Давайте сначала все сделаем, а потом подумаем. Но я бы и добавил \"давайте подумаем\" вдоль всего ноутбука ещё в паре мест. И да, можно же им ничего не объяснять в итоге, а скорее сделать вот так, как у тебя сейчас, пусть сами думают и на форуме обсуждают"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
